<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="A layout example with a side menu that hides on mobile, just like the Pure website.">

    <title>Top 100 Predictor &dash; Final Report</title>

    


<link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.6.0/pure-min.css">
  
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="css/side-menu-old-ie.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="css/side-menu.css">
    <!--<![endif]-->

</head>
<body>






<div id="layout">
    <!-- Menu toggle -->
    <a href="#menu" id="menuLink" class="menu-link">
        <!-- Hamburger icon -->
        <span></span>
    </a>

    <div id="menu">
        <div class="pure-menu">
            <a class="pure-menu-heading">EECS 349</a>

            <ul class="pure-menu-list">
                <li class="pure-menu-item"><a href="index.html" class="pure-menu-link">Home</a></li>
                <li class="pure-menu-item"><a href="#" class="pure-menu-link">Final Report</a></li>
                <li class="pure-menu-item"><a href="contact.html" class="pure-menu-link">Contact Us</a></li>
            </ul>
        </div>
    </div>

    <div id="main">
        <div class="header">
            <h1>Final Report</h1>
            <h2>Our task, our approach, the problems we encountered, and future work we could implement</h2>
            <h3><i>Ally Cody, Kevin Jin, Jaiveer Kothari, and Jeanette Pranin</i></h3>
            <h3><i>EECS 349 &dash; Machine Learning &dash; Northwestern University</i></h3>
        </div>

        <div class="content">
            <h2 class="content-subhead">Our Task</h2>
            <p>
                Our task is to determine whether a song in 2014 will be in the Top 100 songs of the year. For clarity, we will refer to songs that were in the Top 100 as “hits” and songs that were not in the Top 100 as “misses.” Predicting whether or not a song will be a hit is difficult, because song popularity often has to do with how the music makes the audience feel and how “catchy” it is, which is not easy to define. A method for predicting whether a song will be a hit or not, could help artists improve their music or help music labels decide what artists to sign. 
            </p>

            <h2 class="content-subhead">Our Approach</h2>
            <p>
                We used both the Spotify and Echonest APIs to pull songs with various attributes that we believed are most indicative of potential song popularity. The attributes we focused on pulling from the Spotify API were duration, explicitness, number of artists, and the attributes from the Echonest API included danceability, energy, loudness, speechiness, and tempo.
            </p>
            <p>
                Our dataset consists of 1,248 songs which include the songs pulled from the Top 100 tracks of 2014 playlist on spotify. To collect songs that were not hits, we searched on Spotify's API for songs that were released in 2014. We used 70% of our data set to experiment with which classifiers worked best with our type of data, then trained on that 70% and tested on the remaining 30%. There are 873 instances in the training set. For our testing set, we put the remaining 30% of the misses and 30% of the hits and compiled them into the testing data set. We loaded the training set into Weka and ran different classifiers with 10 fold cross validation to find the classifiers and the settings that performed best on that training set. Additionally, we decided to use a cost matrix to weight the classification. This is because there are almost 10 times as many misses than hits, so we want to give more weight to a correctly classified hit. We used a 2x2 cost matrix as this is a binary classification. We tweaked the parameters of each classifier to see what gave us the best results. We then trained on the training set with these three classifiers and tested on the test set.

            </p>

            <h2 class="content-subhead">Our Classifiers</h2>
            <p>
                For our classifiers, we went through Weka and chose the three classifiers that performed best on the data.We chose Naive Bayes, K-Star with globalBlend = 2, and J48 with confidenceFactor = 0.9 and minNumObj = 5.
            </p>
            <p>
                In order to determine the effectiveness of the classifiers, we need a baseline to compare with so we know whether the classifiers are working properly. The baseline we used is the f1-measure of our data set where 50% were randomly classified as a Top 100 track and another 50% as not. The confusion matrix would look like:
            </p>

                <center>
                    <table style="width:50%">
                      <tr>
                        <td></td>
                        <td><i>Classified as Hits</i></td>
                        <td><i>Classified as Misses</i></td>       
                      </tr>
                      <tr>
                        <td><b>Hits</b></td>
                        <td>50</td>     
                        <td>50</td>
                      </tr>
                      <tr>
                        <td><b>Misses</b></td>
                        <td>574</td>        
                        <td>574</td>
                      </tr>
                    </table>
                </center>

            <p>
                The f1-measure is the harmonic mean of the precision and recall. The precision is the ratio of correctly classified Top 100 to the total number of results classified as Top 100, so 50624. The recall is the ratio of correctly classified Top 100 to the total number of actual Top 100 so 50100. The f1-measure is then calculated by taking the harmonic mean which yields 0.1381. This is the baseline that we will look to beat when testing our classifiers.
            </p>
            
            <h2 class="content-subhead">Our Results</h2>
            <center> 
                <table>
                    <tr>
                        <td>
                            <i>Name</i>
                        </td>
                        <td>
                            <i>Cost Matrix</i>
                        </td>
                        <td>
                            <i>Weight Avg Precision</i>
                        </td>
                        <td>
                            <i>Weight Avg Recall</i>
                        </td>
                        <td>
                            <i>Weight Avg f1-Measure</i>
                        </td>
                        <td>
                            <i>Accuracy</i>
                        </td>
                        <td>
                            <i>Confusion Matrix</i>
                        </td>
                    </tr>
                
                    <tr>
                        <td>
                            <b>Naive Bayes</b>
                        </td>
                        <td>
                            <table>
                                <tr>
                                    <td>
                                        0.0
                                    </td>
                                    <td>
                                        1.0
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        2.0
                                    </td>
                                    <td>
                                        0.0
                                    </td>
                                </tr>
                            </table>
                        </td>
                        <td>
                            0.886
                        </td>
                        <td>
                            0.707
                        </td>
                        <td>
                            0.772
                        </td>
                        <td>
                            70.667%
                        </td>
                        <td>
                            <table>
                                <tr>
                                    <td>
                                    </td>
                                    <td>
                                        <i>Classified as Hits</i>
                                    </td>
                                    <td>
                                        <i>Classified as Misses</i>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <b>Hits</b>
                                    </td>
                                    <td>
                                        17
                                    </td>
                                    <td>
                                        13
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <b>Misses</b>
                                    </td>
                                    <td>
                                        97
                                    </td>
                                    <td>
                                        248
                                    </td>
                                </tr>
                            </table>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <b>K-Star with globalBlend = 2</b>
                        </td>
                        <td>
                            <table>
                                <tr>
                                    <td>
                                        0.0
                                    </td>
                                    <td>
                                        1.0
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        3.0
                                    </td>
                                    <td>
                                        0.0
                                    </td>
                                </tr>
                            </table>
                        </td>
                        <td>
                            0.847
                        </td>
                        <td>
                            0.571
                        </td>
                        <td>
                            0.668
                        </td>
                        <td>
                            57.067%
                        </td>
                        <td>
                            <table>
                                <tr>
                                    <td>
                                    </td>
                                    <td>
                                        <i>Classified as Hits</i>
                                    </td>
                                    <td>
                                        <i>Classified as Misses</i>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <b>Hits</b>
                                    </td>
                                    <td>
                                        11
                                    </td>
                                    <td>
                                        19
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <b>Misses</b>
                                    </td>
                                    <td>
                                        142
                                    </td>
                                    <td>
                                        203
                                    </td>
                                </tr>
                            </table>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <b>J48 with confidenceFactor = 0.9, minNumObj = 5</b>
                        </td>
                        <td>
                            <table>
                                <tr>
                                    <td>
                                        0.0
                                    </td>
                                    <td>
                                        1.0
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        4.0
                                    </td>
                                    <td>
                                        0.0
                                    </td>
                                </tr>
                            </table>
                        </td>
                        <td>
                            0.882
                        </td>
                        <td>
                            0.869
                        </td>
                        <td>
                            0.875
                        </td>
                        <td>
                            86.930%
                        </td>
                        <td>
                            <table>
                                <tr>
                                    <td>
                                    </td>
                                    <td>
                                        <i>Classified as Hits</i>
                                    </td>
                                    <td>
                                        <i>Classified as Misses</i>
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <b>Hits</b>
                                    </td>
                                    <td>
                                        9
                                    </td>
                                    <td>
                                        21
                                    </td>
                                </tr>
                                <tr>
                                    <td>
                                        <b>Misses</b>
                                    </td>
                                    <td>
                                        28
                                    </td>
                                    <td>
                                        317
                                    </td>
                                </tr>
                            </table>
                        </td>
                    </tr>
                </table>
            </center>
            <center><img class="pure-img" src="images/confusion_matrix_graph.png"></center>

            <p>
                We built models using cost-sensitive classifier settings in Naive Bayes, K-Star, and J48 on our training set and then analyzed their performance on our test set. The settings used for each classifier and the results are outlined in the table above. Although at first glance it appears that the J48 decision tree performed best with an accuracy of 86.93%, by looking at the confusion matrix it is clear that the higher accuracy of J48 is a result of classifying most songs as misses. While the overall accuracy is high, the accuracy of classifying the hits is low. K-Star, had the lowest accuracy, and although it classified more hits correctly than J48 did, it misclassified many more misses. Ultimately, we believe that Naive Bayes was the best performing classifier, because it classified the hits better than any of the other classifiers.
            </p>
            <p>
                As our datasets had almost 10 times as many misses as there were hits, the percentage of correctly classified instances is not the best way to measure the success of our model. We decided that f1-measure would be a better metric. In our opinion, the classifier that best classified our data was Naive Bayes with an f1-measure of 0.772.
            </p>

            <h2 class="content-subhead">Problems We Encountered</h2>
            <p>
                At first we believed that pulling from Spotify alone would give us the attributes needed to successfully predict the Top 100 songs of 2014. However, the information available on the Spotify API did not adequately describe any audio features we thought would be useful in our prediction. However, certain attributes such as artist explicitness and duration of the song, among others, were ones Spotify provided that we felt were necessary. We solved this by incorporating these attributes from Spotify with the data we pulled from Echonest.
            </p>
            <p>
                Another problem we faced was that Spotify had a limit of pulling 50 songs per query and Echonest a limit of 20 songs per minute, but we needed at least 1000 songs for our predictor to have a large enough training set. We worked around the Spotify issue by searching through the tracks by each letter of the alphabet (for example, any track that had the letter 'a' in its title), accumulating the results from these queries into jsons, and deleting duplicates. We fixed the Echonest issue by putting a timer in our code that stopped the code for one minute from running after 20 songs were pulled. This was quite a difficult problem to work around, as our code ran for 30+ minutes and we would not find bugs in our code instantly.
            </p>

        </div>
    </div>
</div>





<script src="js/ui.js"></script>


</body>
</html>
